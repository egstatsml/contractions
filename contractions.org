#+PROPERTY: header-args:jupyter-python  :session  /home/ethan/.local/share/jupyter/runtime/kernel-cacfdf90-f711-4ed9-8ec6-2d93cbfef53e.json
#+title: Contractions

I don't like typing apostrophes. Making my pinky do extra work  and stretching far all the time makes me sad.   This notebook is an attempt to alleviate
that sadness.

I live inside Emacs, so have the flexibility to incorporate some my own logic to address my woes. The current plan of attack is;
1. Find list of most common used words
   1. Find top "n" words with apostrophes
      1. Put them into an abbrev table with the appostrophes removed, and let Emacs and abbrev do the heavy lifting for me.

** Word list
I am going  to use the word list from [[https://github.com/IlyaSemenov/wikipedia-word-frequency][Wikipedia Word Frequency]] to help me find words with apostrophes. This package also has an order to let us know how common
the words are, so I can say just get the top 1000 words with apostrophes.

I have made this repo a submodule, which includes the list  [[file:wikipedia-word-frequency/results/enwiki-20210820-words-frequency.txt][from 2021 analysis here]].
I am going to filter out to just get the samples with  apostrophes.

#+begin_src bash
  grep \' wikipedia-word-frequency/results/enwiki-20210820-words-frequency.txt >> apostrophe_list.txt
#+end_src

#+RESULTS:

This will result in a file with the format of
#+begin_src
<word> <frequency>
#+end_src
which is essentially a csv file except with spaces, and is ordered so that the most frequent words will be at the top.

I am going to use python to process this, as am more comfortable with that.
    #+begin_src python :results raw
      import pandas as pd

      def remove_apostrophe(row):
          """act on row of dataframe to remove apostrophes.

          Words with apostrophes removed will be placed in the "removed" column.

          Parameters
          ----------
          row : pd.Series
              Row from the dataframe of interest.

          Examples
          --------
          FIXME: Add docs.
          """
          return row.word.replace("\'", "")

      print("here")
      # load in the file with apostrophes
      wikipedia_df = pd.read_csv("apostrophe_list.txt", sep=" ", names=["word", "frequency"])
      # let's add an empty column to contain the words without apostrophes.
      wikipedia_df["removed"] = wikipedia_df.apply(remove_apostrophe, axis=1)

      print(wikipedia_df.head())
      print(wikipedia_df.shape)
    #+end_src

    #+RESULTS:
    None
    None


    #+begin_src jupyter-python
      import pandas as pd
      import os
      os.chdir("/home/ethan/code/contractions")
      print(os.getcwd())
      # load in the file with apostrophes
      wikipedia_df = pd.read_csv("./apostrophe_list.txt", sep=" ", names=["word", "frequency"])
      # let's add an empty column to contain the words without apostrophes.
      print(wikipedia_df.head())
      print(wikipedia_df.shape)
    #+end_src

    #+RESULTS:
    : /home/ethan/code/contractions
    :          word  frequency
    : 0     women's     503960
    : 1       men's     354399
    : 2        it's     228179
    : 3    people's     152424
    : 4  children's     137591
    : (173030, 2)
    This results in a pretty big list of words with apostrophes. Lets have a look at some them to see what they are like.
    #+begin_src jupyter-python
      import numpy as np
      # let's have a look at say every thousandth word.
      idx = np.linspace(1000, wikipedia_df.shape[0], 100).astype(np.int64)
      idx = np.linspace(0, 100, 100).astype(np.int64)
      for i in idx:
          print(f"idx: {i}, word: {wikipedia_df.word.iloc[i]}")

    #+end_src

    #+RESULTS:
    #+begin_example
      idx: 0, word: women's
      idx: 1, word: men's
      idx: 2, word: it's
      idx: 3, word: people's
      idx: 4, word: children's
      idx: 5, word: don't
      idx: 6, word: band's
      idx: 7, word: city's
      idx: 8, word: world's
      idx: 9, word: didn't
      idx: 10, word: company's
      idx: 11, word: father's
      idx: 12, word: king's
      idx: 13, word: i'm
      idx: 14, word: club's
      idx: 15, word: team's
      idx: 16, word: country's
      idx: 17, word: album's
      idx: 18, word: school's
      idx: 19, word: master's
      idx: 20, word: film's
      idx: 21, word: doesn't
      idx: 22, word: that's
      idx: 23, word: group's
      idx: 24, word: state's
      idx: 25, word: year's
      idx: 26, word: can't
      idx: 27, word: party's
      idx: 28, word: he's
      idx: 29, word: university's
      idx: 30, word: queen's
      idx: 31, word: government's
      idx: 32, word: wasn't
      idx: 33, word: bachelor's
      idx: 34, word: john's
      idx: 35, word: mary's
      idx: 36, word: one's
      idx: 37, word: show's
      idx: 38, word: mother's
      idx: 39, word: game's
      idx: 40, word: town's
      idx: 41, word: there's
      idx: 42, word: nation's
      idx: 43, word: america's
      idx: 44, word: family's
      idx: 45, word: you're
      idx: 46, word: australia's
      idx: 47, word: today's
      idx: 48, word: i've
      idx: 49, word: station's
      idx: 50, word: canada's
      idx: 51, word: league's
      idx: 52, word: she's
      idx: 53, word: o'brien
      idx: 54, word: song's
      idx: 55, word: man's
      idx: 56, word: isn't
      idx: 57, word: we're
      idx: 58, word: couldn't
      idx: 59, word: ship's
      idx: 60, word: india's
      idx: 61, word: paul's
      idx: 62, word: china's
      idx: 63, word: woman's
      idx: 64, word: army's
      idx: 65, word: earth's
      idx: 66, word: george's
      idx: 67, word: god's
      idx: 68, word: president's
      idx: 69, word: peter's
      idx: 70, word: they're
      idx: 71, word: smith's
      idx: 72, word: season's
      idx: 73, word: district's
      idx: 74, word: london's
      idx: 75, word: magazine's
      idx: 76, word: church's
      idx: 77, word: britain's
      idx: 78, word: germany's
      idx: 79, word: o'connor
      idx: 80, word: japan's
      idx: 81, word: husband's
      idx: 82, word: won't
      idx: 83, word: player's
      idx: 84, word: society's
      idx: 85, word: what's
      idx: 86, word: person's
      idx: 87, word: county's
      idx: 88, word: let's
      idx: 89, word: o'neill
      idx: 90, word: wouldn't
      idx: 91, word: york's
      idx: 92, word: building's
      idx: 93, word: character's
      idx: 94, word: island's
      idx: 95, word: i'll
      idx: 96, word: court's
      idx: 97, word: latter's
      idx: 98, word: organization's
      idx: 100, word: who's
    #+end_example

    Is some useful words here, but it looks like it might be missing a lot of words relevent for first person writing, which I still need. To try and alleviate this,  am going to include some of the words from the [[http://wordlist.aspell.net/scowl-readme/][SCOWL]] word lists, particularly the list of contractions.

   First lets load in all the contraction words and drop any duplicates.

   #+begin_src jupyter-python
     data_dir = "/home/ethan/data/scowl-2020.12.07"
     # get names of all the contraction files
     import glob
     contraction_files = glob.glob(data_dir + "/final/*contraction*")
     scowl_file = os.path.join("/home/ethan/code/contractions/scowl_contractions_combined.txt")
     with open(scowl_file, "w") as outfile:
         for file_path in contraction_files:
             with open(file_path, "r") as infile:
                 for line in infile:
                     outfile.write(line)
   #+end_src

   #+RESULTS:

   Let's now combine these lists.
   I want to first trim down the original list, maybe keep the first 1000 most common. Will then combine and them remove any duplicates.

   #+begin_src jupyter-python
     wikipedia_1000_df = wikipedia_df.iloc[0:1000, :]
     # now lets load in the scowl contractions
     scowl_df = pd.read_csv(scowl_file, names=["word"])
     scowl_df['frequency'] = 0
     scowl_df.head()
   #+end_src

   #+RESULTS:
   :          word  frequency
   : 0  Hallowe'en          0
   : 1      bo's'n          0
   : 2     bo's'ns          0
   : 3      bo'sun          0
   : 4     bo'suns          0


Now lets combine them and remove any duplicates.
#+begin_src jupyter-python
    combined_df = pd.concat([wikipedia_1000_df, scowl_df])
    combined_df.head()
#+end_src

#+RESULTS:
:          word  frequency
: 0     women's     503960
: 1       men's     354399
: 2        it's     228179
: 3    people's     152424
: 4  children's     137591

Now lets create a column with the apostrophes removed.
#+begin_src jupyter-python
  def remove_apostrophe(row):
      """act on row of dataframe to remove apostrophes.

      Words with apostrophes removed will be placed in the "removed" column.

      Parameters
      ----------
      row : pd.Series
          Row from the dataframe of interest.

      Examples
      --------
      FIXME: Add docs.
      """
      return row.word.replace("\'", "")

  combined_df['removed'] = combined_df.apply(remove_apostrophe, axis=1)
  # want to remove any duplicates
  combined_df = combined_df.drop_duplicates(subset=['word'])
  combined_df.head()
  print(combined_df.iloc[1000::, :])
#+end_src

#+RESULTS:
#+begin_example
  (1196, 3)
             word  frequency    removed
  0    Hallowe'en          0  Halloween
  1        bo's'n          0       bosn
  2       bo's'ns          0      bosns
  3        bo'sun          0      bosun
  4       bo'suns          0     bosuns
  ..          ...        ...        ...
  253  wolf'smilk          0  wolfsmilk
  254       x'ing          0       xing
  255       ye'se          0       yese
  256      your'n          0      yourn
  257    Qur'anic          0    Quranic

  [196 rows x 3 columns]
  /tmp/ipykernel_60823/1059449099.py:17: SettingWithCopyWarning:
  A value is trying to be set on a copy of a slice from a DataFrame.
  Try using .loc[row_indexer,col_indexer] = value instead

  See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
    combined_df['removed'] = combined_df.apply(remove_apostrophe, axis=1)
#+end_example

I now want to create this into a list that is suitable for abbrev mode within emacs.
Going to save it to file in suitable elisp format.

#+begin_src jupyter-python
  # create the abbrev file
  abbrev_file = "/home/ethan/code/contractions/abbrev_contractions.txt"
  with open(abbrev_file, 'w') as abb_file:
     for _, row in combined_df.iterrows():
        abb_file.writelines(f'(\"{row.removed}\" \"{row.word}\")\n')
#+end_src

